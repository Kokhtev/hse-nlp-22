{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5gdesnpaKkI"
   },
   "source": [
    "# Инструменты для работы с языком"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiVyYrRKaKkO"
   },
   "source": [
    "... или зачем нужна предобработка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaFtte40aKkO"
   },
   "source": [
    "## Задача: классификация твитов по тональности\n",
    "\n",
    "У нас есть датасет из твитов, про каждый указано, как он эмоционально окрашен: положительно или отрицательно. Задача: предсказывать эмоциональную окраску.\n",
    "\n",
    "Классификацию по тональности используют в рекомендательных системах, чтобы понять, понравилось ли людям кафе, кино, etc.\n",
    "\n",
    "Скачиваем куски датасета ([источник](http://study.mokoron.com/)): [положительные](https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0), [отрицательные](https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "voAEorlraKkO",
    "outputId": "bf19b846-66c1-4d95-cc79-422502c59d34"
   },
   "outputs": [],
   "source": [
    "# если у вас линукс / мак / collab или ещё какая-то среда, в которой работает wget, можно так:\n",
    "# ! wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
    "# ! wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pDzOeZedIGew",
    "outputId": "86fb93c4-efa4-4218-acea-3fbbd054e62c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice.txt\r\n",
      "clean_text.txt\r\n",
      "\u001b[34mfastText\u001b[m\u001b[m\r\n",
      "negative.csv\r\n",
      "positive.csv\r\n",
      "ru_analogy_tagged.txt\r\n",
      "ruscorpora_mystem_cbow_300_2_2015.bin.gz\r\n",
      "sem03_preprocessing.ipynb\r\n",
      "sem04_embeddings.ipynb\r\n",
      "unlabeledTrainData.tsv\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ofqi32cqaKkP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cV-BobU6IP5L",
    "outputId": "f1471c1e-6df4-4ae3-a02c-f300100d9ea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"408906692374446080\";\"1386325927\";\"pleease_shut_up\";\"@first_timee хоть я и школота, но поверь, у нас то же самое :D общество профилирующий предмет типа)\";\"1\";\"0\";\"0\";\"0\";\"7569\";\"62\";\"61\";\"0\"\r",
      "\r\n",
      "\"408906692693221377\";\"1386325927\";\"alinakirpicheva\";\"Да, все-таки он немного похож на него. Но мой мальчик все равно лучше:D\";\"1\";\"0\";\"0\";\"0\";\"11825\";\"59\";\"31\";\"2\"\r",
      "\r\n",
      "\"408906695083954177\";\"1386325927\";\"EvgeshaRe\";\"RT @KatiaCheh: Ну ты идиотка) я испугалась за тебя!!!\";\"1\";\"0\";\"1\";\"0\";\"1273\";\"26\";\"27\";\"0\"\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! head -3 positive.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZUGYGV-XaKkQ"
   },
   "outputs": [],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = positive.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "id": "pxoUd977aKkQ",
    "outputId": "43938ec6-3dfd-4f0e-a816-636673c9ab71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111918</th>\n",
       "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111919</th>\n",
       "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111920</th>\n",
       "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111921</th>\n",
       "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111922</th>\n",
       "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text     label\n",
       "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
       "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
       "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
       "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
       "111922  Такси везет меня на работу. Раздумываю приплат...  negative"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JZVrcWpoaKkQ"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOqlVlAXaKkR"
   },
   "source": [
    "## Baseline: классификация необработанных n-грамм\n",
    "\n",
    "### Векторизаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wW9Zy5-1aKkR"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DC3z8WhEaKkR"
   },
   "source": [
    "Что такое n-граммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xOJ7dsukaKkR"
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VZzKR4__aKkS",
    "outputId": "dea59748-da57-4bfd-d618-9b7314fbc207"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Если б мне платили каждый раз'.split()\n",
    "list(ngrams(sent, 1)) # униграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czD9_lhEaKkS",
    "outputId": "2b85d091-e2bf-44f6-a77c-9010aedb59d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б'),\n",
       " ('б', 'мне'),\n",
       " ('мне', 'платили'),\n",
       " ('платили', 'каждый'),\n",
       " ('каждый', 'раз')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 2)) # биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vxb_K9vfaKkS",
    "outputId": "ea95565b-e763-4a9e-aa94-8bccdb032809"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне'),\n",
       " ('б', 'мне', 'платили'),\n",
       " ('мне', 'платили', 'каждый'),\n",
       " ('платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 3)) # триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_PxhPUjhaKkT",
    "outputId": "f807633b-ca62-4dbb-ca47-63803272c2b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
       " ('б', 'мне', 'платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 5)) # ... пентаграммы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2LByfoCaKkT"
   },
   "source": [
    "Самый простой способ извлечь фичи из текстовых данных -- векторизаторы: `CountVectorizer` и `TfidfVectorizer`\n",
    "\n",
    "Объект `CountVectorizer` делает простую вещь:\n",
    "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грам во всём корпусе\n",
    "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Xlqu8U89aKkU"
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QW6sI7TyKDkR",
    "outputId": "70f9798e-63a6-47cd-c349-605b27104a42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82819     Один шматок, чтобы править всеми :DDDD http://...\n",
       "91734     @flashing_amber блииин. Надо было его в большо...\n",
       "14033     @SeregaSelibakin писала на протяжении недели, ...\n",
       "107324        @saschyulya я уже написала кое кому..прости((\n",
       "88865     Мы в Яремче,спим на полу умываемся в холодной ...\n",
       "                                ...                        \n",
       "61990     @ANNA_SEDOKOVA ну это хорошая затея.....главно...\n",
       "20227     Шизик и Буряк лошары, они чаще всего проигрыва...\n",
       "17154     RT @HoranMary98: мне понравилось спорить с ней...\n",
       "7471      @Natashlii  який він кайфовий)  Я тащусь від н...\n",
       "4042              \"@nailya1106: Я так хочу ему позвонить;(\"\n",
       "Name: text, Length: 170125, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YV7blJc1J5f_",
    "outputId": "98c0c782-507c-477f-9836-f1b18b4059f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<170125x243604 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1848001 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OR0-dy6aKkU"
   },
   "source": [
    "ngram_range отвечает за то, какие n-граммы мы используем в качестве фичей:<br/>\n",
    "ngram_range=(1, 1) -- униграммы<br/>\n",
    "ngram_range=(3, 3) -- триграммы<br/>\n",
    "ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
    "\n",
    "В vec.vocabulary_ лежит словарь: мэппинг слов к их индексам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OaFys6NmaKkU",
    "outputId": "0f2f67af-6ae9-4146-e47d-a546f463bee7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('один', 172274),\n",
       " ('шматок', 239156),\n",
       " ('чтобы', 237500),\n",
       " ('править', 191734),\n",
       " ('всеми', 115417),\n",
       " ('dddd', 24270),\n",
       " ('http', 38053),\n",
       " ('co', 21452),\n",
       " ('lrpjfvemcj', 53430),\n",
       " ('flashing_amber', 31908)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vec.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M8y8hxAWaKkV",
    "outputId": "ad8e2138-f7b3-4e69-fa89-c5974dae0e52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEOT8_8LaKkV",
    "outputId": "27169d1d-7d61-41ce-b1dc-c9813de52151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.76      0.76     28240\n",
      "    positive       0.76      0.77      0.77     28469\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p6N8VTMDaKkV",
    "outputId": "93503252-4001-4d19-e43a-c827c968bbad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IF0zbX0aKkW",
    "outputId": "b65e0165-471e-44d6-a645-0b8f1f03a0f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': 42,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JD99n4E1aKkW",
    "outputId": "84eb2f66-3a66-41c6-9867-2558b2e4fa84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C',\n",
       " '_check_n_features',\n",
       " '_estimator_type',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_predict_proba_lr',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_validate_data',\n",
       " 'class_weight',\n",
       " 'classes_',\n",
       " 'coef_',\n",
       " 'decision_function',\n",
       " 'densify',\n",
       " 'dual',\n",
       " 'fit',\n",
       " 'fit_intercept',\n",
       " 'get_params',\n",
       " 'intercept_',\n",
       " 'intercept_scaling',\n",
       " 'l1_ratio',\n",
       " 'max_iter',\n",
       " 'multi_class',\n",
       " 'n_features_in_',\n",
       " 'n_iter_',\n",
       " 'n_jobs',\n",
       " 'penalty',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'random_state',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'solver',\n",
       " 'sparsify',\n",
       " 'tol',\n",
       " 'verbose',\n",
       " 'warm_start']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v for v in dir(clf) if '__' not in v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVnXZa7LaKkW"
   },
   "source": [
    "Попробуем сделать то же самое для триграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yl8jxXdraKkW",
    "outputId": "e696ff4d-7924-4436-f1ef-c801b83d2408"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.71      0.57     18272\n",
      "    positive       0.82      0.61      0.70     38437\n",
      "\n",
      "    accuracy                           0.65     56709\n",
      "   macro avg       0.64      0.66      0.63     56709\n",
      "weighted avg       0.71      0.65      0.66     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(3, 3))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a6UqDk1Kc0t",
    "outputId": "bc0cc580-1182-484b-ebbe-6efe1da47f92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<170125x1328616 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1557368 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLOOazSxaKkW"
   },
   "source": [
    "(как вы думаете, почему в результатах теперь такой разброс по сравнению с униграммами?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qX6oLFxSaKkX"
   },
   "source": [
    "## TF-IDF векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yqR5QKDaKkX"
   },
   "source": [
    "`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений – tf-idf каждого слова.\n",
    "\n",
    "Как считается tf-idf:\n",
    "\n",
    "TF (term frequency) – относительная частотность слова в документе:\n",
    "$$ TF(t,d) = \\frac{n_{t}}{\\sum_k n_{k}} $$\n",
    "\n",
    "IDF (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
    "$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
    "\n",
    "Перемножаем их:\n",
    "$$TFIDF_(t,d,D) = TF(t,d) \\times IDF(i, D)$$\n",
    "\n",
    "Сакральный смысл – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом \n",
    "количестве документов, у него высокий TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "eSNwwAXKaKkX"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZASM2nwOaKkX",
    "outputId": "8970dccc-3059-45ba-862d-09218abc2b17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.77      0.75     26691\n",
      "    positive       0.78      0.75      0.77     30018\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAjEwrbraKkX"
   },
   "source": [
    "В этот раз получилось хуже :( Вернёмся к `CountVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7aEEg0zaKkY"
   },
   "source": [
    "## Токенизация\n",
    "\n",
    "Токенизировать -- значит, поделить текст на слова, или *токены*.\n",
    "\n",
    "Самый наивный способ токенизировать текст -- разделить с помощью `split`. Но `split` упускает очень много всего, например, банально не отделяет пунктуацию от слов. Кроме этого, есть ещё много менее тривиальных проблем. Поэтому лучше использовать готовые токенизаторы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "U1iJIXmJaKkZ"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nv27iLNFLaxP",
    "outputId": "6f384aa6-0744-48c0-a3ed-ef53df10a702"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/vkokhtev/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6J76W1nTaKkZ",
    "outputId": "880686d0-6a9d-4544-92c5-e4a456a8615e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Но', 'не', 'каждый', 'хочет', 'что-то', 'исправлять', ':', '(']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 'Но не каждый хочет что-то исправлять:('\n",
    "word_tokenize(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rheXniB4aKka"
   },
   "source": [
    "В nltk вообще есть довольно много токенизаторов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LcrGx3MSaKka",
    "outputId": "37f31b13-6384-4265-b4ca-58b006c2ad11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BlanklineTokenizer',\n",
       " 'LineTokenizer',\n",
       " 'MWETokenizer',\n",
       " 'NLTKWordTokenizer',\n",
       " 'PunktSentenceTokenizer',\n",
       " 'RegexpTokenizer',\n",
       " 'ReppTokenizer',\n",
       " 'SExprTokenizer',\n",
       " 'SpaceTokenizer',\n",
       " 'StanfordSegmenter',\n",
       " 'SyllableTokenizer',\n",
       " 'TabTokenizer',\n",
       " 'TextTilingTokenizer',\n",
       " 'ToktokTokenizer',\n",
       " 'TreebankWordTokenizer',\n",
       " 'TweetTokenizer']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "dir(tokenize)[:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41SP4TjtaKka"
   },
   "source": [
    "Они умеют выдавать индексы начала и конца каждого токена:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qzivTseTaKka",
    "outputId": "e7eb474b-7d3b-4f16-85b6-89657f5a6ff9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2), (3, 5), (6, 12), (13, 18), (19, 25), (26, 38)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wh_tok = tokenize.WhitespaceTokenizer()\n",
    "list(wh_tok.span_tokenize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NMC50_SaKkb"
   },
   "source": [
    "(если вам было интересно, зачем вообще включать в модуль токенизатор, который работает как `.split()` :))\n",
    "\n",
    "Некторые токенизаторы ведут себя специфично:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MrANQrYEaKkb",
    "outputId": "297f06c0-7543-4d38-e5a0-87eb27ebba38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do', \"n't\", 'stop', 'me']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.TreebankWordTokenizer().tokenize(\"don't stop me\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0P3ZgRGaKkb"
   },
   "source": [
    "Для некоторых задач это может быть полезно.\n",
    "\n",
    "А некоторые -- вообще не для текста на естественном языке (не очень понятно, зачем это в nltk :)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CpQ4qBHKaKkb",
    "outputId": "100f7cbb-5f11-4050-fa4c-2815e0f0c16e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(a (b c))', 'd', 'e', '(f)']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.SExprTokenizer().tokenize(\"(a (b c)) d e (f)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQpEx2-faKkc"
   },
   "source": [
    "## Стоп-слова и пунктуация\n",
    "\n",
    "*Стоп-слова* -- это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе, то есть играют роль шума. Поэтому их принято убирать. По той же причине убирают и пунктуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-uby04IZMDkZ",
    "outputId": "bc46c543-cbc5-4210-af3a-c5b4f16b4049"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vkokhtev/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVNTn6lPaKkc",
    "outputId": "9cd11658-6eda-40fe-80eb-2b02eb1b0fe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "# у вас здесь, вероятно, выскочит ошибка и надо будет загрузить стоп слова (в тексте ошибки написано, как)\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "e69-5JuJaKkc",
    "outputId": "f8cef1d4-d482-45c1-a0bd-0d24ee328b58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "9fSXKqR5aKkc"
   },
   "outputs": [],
   "source": [
    "noise = stopwords.words('russian') + list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJmoTxpqaKkd"
   },
   "source": [
    "В векторизаторах за стоп-слова, логичным образом, отвечает аргумент `stop_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQQFbxQQaKkd",
    "outputId": "8b7912df-8f5a-4475-ed94-4481650ce891"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.76      0.78     29173\n",
      "    positive       0.76      0.80      0.78     27536\n",
      "\n",
      "    accuracy                           0.78     56709\n",
      "   macro avg       0.78      0.78      0.78     56709\n",
      "weighted avg       0.78      0.78      0.78     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_53DgfhqaKkd"
   },
   "source": [
    "Получилось чууть лучше. Что ещё можно сделать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBcgiLfRaKkd"
   },
   "source": [
    "## Лемматизация\n",
    "\n",
    "Лемматизация – это сведение разных форм одного слова к начальной форме – *лемме*. Почему это хорошо?\n",
    "* Во-первых, мы хотим рассматривать как отдельную фичу каждое *слово*, а не каждую его отдельную форму.\n",
    "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n",
    "\n",
    "Для русского есть два хороших лемматизатора: mystem и pymorphy:\n",
    "\n",
    "### [Mystem](https://tech.yandex.ru/mystem/)\n",
    "Как с ним работать:\n",
    "* можно скачать mystem и запускать [из терминала с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
    "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "FSLdWYFjaKkd"
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem_analyzer = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8J6utcSaKkd"
   },
   "source": [
    "Мы инициализировали Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
    "* mystem_bin - путь к `mystem`, если их несколько\n",
    "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
    "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
    "* entire_input - нужно ли сохранять в выводе все (пробелы всякие, например), или можно выкинуть (по дефолту оставляется все)\n",
    "\n",
    "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
    "\n",
    "Можно просто лемматизировать текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "WEkno0bSNwOR",
    "outputId": "d5145f4a-70ee-420c-90dc-c3c9527f39fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Но не каждый хочет что-то исправлять:('"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "M5EMmGzVaKkd",
    "outputId": "4ad90cf1-7922-42e9-aa28-3a3aa56fb91a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['но', ' ', 'не', ' ', 'каждый', ' ', 'хотеть', ' ', 'что-то', ' ', 'исправлять', ':(\\n']\n"
     ]
    }
   ],
   "source": [
    "print(mystem_analyzer.lemmatize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hj0ODpk3aKkd"
   },
   "source": [
    "А можно получить грамматическую информацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "3FJOdjteaKkd",
    "outputId": "b2ba60ff-2d9a-4d31-836f-746496b7d676"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'но', 'wt': 0.9998906299, 'gr': 'CONJ='}],\n",
       "  'text': 'Но'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'не', 'wt': 1, 'gr': 'PART='}], 'text': 'не'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'каждый',\n",
       "    'wt': 0.9985975799,\n",
       "    'gr': 'APRO=(вин,ед,муж,неод|им,ед,муж)'}],\n",
       "  'text': 'каждый'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'хотеть',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,несов,пе=непрош,ед,изъяв,3-л'}],\n",
       "  'text': 'хочет'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'что-то', 'wt': 1, 'gr': 'SPRO,ед,сред,неод=(вин|им)'}],\n",
       "  'text': 'что-то'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'исправлять', 'wt': 1, 'gr': 'V,пе=инф,несов'}],\n",
       "  'text': 'исправлять'},\n",
       " {'text': ':(\\n'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPX2Q_TgaKke"
   },
   "source": [
    "Давайте терепь лемматизатор майстема в качестве токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Vdlu7Yl5aKke"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def my_preproc(text):\n",
    "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
    "    text = mystem_analyzer.lemmatize(text)\n",
    "    return [word for word in text if word not in stopwords.words('russian') + [' ', '\\n']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "ln-Mxux7aKke",
    "outputId": "86e36c17-77bf-488a-a88b-2b97db1f1fe8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.74      0.76     28907\n",
      "    positive       0.74      0.77      0.76     27802\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTEvgIxbaKke"
   },
   "source": [
    "### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n",
    "Это модуль на питоне, довольно быстрый и с кучей функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-dEpZ70OOYeE",
    "outputId": "50db7dc5-278c-426b-92b5-453f55b68acf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/lib/python3.8/site-packages\n",
      "sysconfig: /usr/local/Cellar/python@3.8/3.8.6/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/lib/python3.8/site-packages\n",
      "sysconfig: /usr/local/Cellar/python@3.8/3.8.6/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/include/python3.8/UNKNOWN\n",
      "sysconfig: /usr/local/Cellar/python@3.8/3.8.6/Frameworks/Python.framework/Versions/3.8/include/python3.8/UNKNOWN\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local/bin\n",
      "sysconfig: /usr/local/Cellar/python@3.8/3.8.6/Frameworks/Python.framework/Versions/3.8/bin\u001b[0m\n",
      "\u001b[33mWARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "distutils: /usr/local\n",
      "sysconfig: /usr/local/Cellar/python@3.8/3.8.6/Frameworks/Python.framework/Versions/3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Collecting pymorphy2\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docopt>=0.6\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.2 MB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dawg-python>=0.7.1\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13724 sha256=08ccefcb8f51819b257b49f31a12de2358ce42b657cea213d016c6626c7e53ee\n",
      "  Stored in directory: /Users/vkokhtev/Library/Caches/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "Successfully built docopt\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
      "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.8/pymorphy2-dicts-ru\n",
      "  sysconfig: /usr/local/Cellar/python@3.8/3.8.6/Frameworks/Python.framework/Versions/3.8/include/python3.8/pymorphy2-dicts-ru\u001b[0m\n",
      "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.8/docopt\n",
      "  sysconfig: /usr/local/Cellar/python@3.8/3.8.6/Frameworks/Python.framework/Versions/3.8/include/python3.8/docopt\u001b[0m\n",
      "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.8/dawg-python\n",
      "  sysconfig: /usr/local/Cellar/python@3.8/3.8.6/Frameworks/Python.framework/Versions/3.8/include/python3.8/dawg-python\u001b[0m\n",
      "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
      "  distutils: /usr/local/include/python3.8/pymorphy2\n",
      "  sysconfig: /usr/local/Cellar/python@3.8/3.8.6/Frameworks/Python.framework/Versions/3.8/include/python3.8/pymorphy2\u001b[0m\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n",
      "\u001b[33mWARNING: You are using pip version 21.2.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Bd5noU2SaKke"
   },
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "pymorphy2_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxcZOXkpaKke"
   },
   "source": [
    "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T3QKPNVOaKkf",
    "outputId": "07615d5b-e50a-47a0-ffb4-c056ebedc4e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='платили', tag=OpencorporaTag('VERB,impf,tran plur,past,indc'), normal_form='платить', score=1.0, methods_stack=((DictionaryAnalyzer(), 'платили', 2472, 10),))]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana = pymorphy2_analyzer.parse(sent[3])\n",
    "ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "7KwUrK_GaKkf",
    "outputId": "17746ed3-070a-46f6-bc41-703c2f5d7148"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'платить'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana[0].normal_form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPKbIKapaKkf"
   },
   "source": [
    "А теперь напишите аналогичную функцию для лемматизации с pymorphy2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "QBmwCzlNaKkf"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def my_preproc(text):\n",
    "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
    "    text = [pymorphy2_analyzer.parse(elem)[0].normal_form for elem in text.split()]\n",
    "    return [word for word in text if word not in stopwords.words('russian') + [' ', '\\n']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cioPjmqFaKkf"
   },
   "source": [
    "Что будет, если использовать её в качестве препроцессора? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "fxBh0Tg2aKkf",
    "outputId": "aabad4c0-dcfe-43f6-f3a4-3d82fb922a4c",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-8fbdae5300e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_preproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[1;32m   1199\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-22db324a3ce1>\u001b[0m in \u001b[0;36mmy_preproc\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmy_preproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[{}]'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpymorphy2_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_form\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'russian'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-22db324a3ce1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmy_preproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[{}]'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpymorphy2_analyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_form\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'russian'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pymorphy2/analyzer.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_to_parses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pymorphy2/analyzer.py\u001b[0m in \u001b[0;36mapply_to_parses\u001b[0;34m(self, word, word_lower, parses)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;31m# no P(t|w) information is available; return normalized estimate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_score_getter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             return [\n\u001b[1;32m     84\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormal_form\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethods_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tiKqCK-aKkf"
   },
   "source": [
    "### mystem vs. pymorphy\n",
    "\n",
    "1) *Мы надеемся, что вы пользуетесь линуксом*, но mystem работает невероятно медленно под windows на больших текстах.\n",
    "\n",
    "2) *Снятие омонимии*. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "os13g1poaKkf",
    "outputId": "e4b428ce-274e-4ab0-d5d4-7cb6fb1612b4"
   },
   "outputs": [],
   "source": [
    "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
    "homonym2 = 'Сорока своровала блестящее украшение со стола.'\n",
    "mystem_analyzer = Mystem() # инициализирую объект с дефолтными параметрами\n",
    "\n",
    "print(mystem_analyzer.analyze(homonym1)[-5])\n",
    "print(mystem_analyzer.analyze(homonym2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bb4nbDW0aKkf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvlM_otlaKkg"
   },
   "source": [
    "## Словарь, закон Ципфа и закон Хипса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7_uy1_KaKkg"
   },
   "source": [
    "Закон Ципфа -- эмпирическая закономерность: если все слова корпуса текста упорядочить по убыванию частоты их использования, то частота n-го слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру n. Иными словами, частотность слов убывает очень быстро."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "XX3NATvmaKkg"
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "1v1GgeT6aKkg",
    "outputId": "79c8f6a5-8f9d-4cb6-860d-2bd0486b9c22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2870536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['first_timee', 'хоть', 'я', 'и', 'школота', 'но', 'поверь', 'у', 'нас', 'то']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
    "print(len(corpus))\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "nPpxxAoVaKkg",
    "outputId": "29eb5e87-6171-4015-8f63-2bacbe9c7682"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('не', 69472),\n",
       " ('и', 55166),\n",
       " ('в', 52902),\n",
       " ('я', 52818),\n",
       " ('RT', 38070),\n",
       " ('на', 35759),\n",
       " ('http', 32998),\n",
       " ('что', 31541),\n",
       " ('с', 27217),\n",
       " ('а', 26860)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = Counter(corpus)\n",
    "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
    "list(freq_dict_sorted)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "N_T00HJ8aKkg",
    "outputId": "7cf8c893-8232-44b3-d60d-8782d6194c55"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "first_100_freqs = [freq for word, freq in freq_dict_sorted[:100]]\n",
    "plt.plot(first_100_freqs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLqGcFLlaKkg"
   },
   "source": [
    "Закон Хипса -- обратная сторона закона Ципфа. Он описывает, что чем больше корпус, тем меньше новых слов добавляется с добавлением новых текстов. В какой-то момент корпус насыщается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nio32SdsaKkg"
   },
   "source": [
    "## О важности эксплоративного анализа\n",
    "\n",
    "Но иногда пунктуация бывает и не шумом -- главное отталкиваться от задачи. Что будет если вообще не убирать пунктуацию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "m4nCGmJIaKkg",
    "outputId": "70b5ab0d-b68f-47c2-bba6-24166fad7de5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     27778\n",
      "    positive       1.00      1.00      1.00     28931\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzoFVFV3aKkh"
   },
   "source": [
    "Шок! Стоило оставить пунктуацию -- и все метрики равны 1. Как это получилось? Среди неё были очень значимые токены (как вы думаете, какие?). Найдите фичи с самыми большими коэффициэнтами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKXycNXBR1zj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXNLdYH4aKkh"
   },
   "source": [
    "Посмотрим, как один из супер-значительных токенов справится с классификацией безо всякого машинного обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNrvbPRaaKkh",
    "outputId": "099525d6-4dae-4c24-d3f1-29163711494b"
   },
   "outputs": [],
   "source": [
    "cool_token = \n",
    "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deG1h_3TaKkh"
   },
   "source": [
    "## Символьные n-граммы\n",
    "\n",
    "Теперь в качестве фичей используем, например, униграммы символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vp8xL8yaaKkh",
    "outputId": "46197a7b-c96f-4e8b-9ca2-5538b4663d8b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      1.00     27739\n",
      "    positive       1.00      0.99      1.00     28970\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHS5xipVaKkh"
   },
   "source": [
    "В общем-то, теперь уже понятно, почему на этих данных здесь 1. Так или инчае, на символах классифицировать тоже можно: для некторых задач (например, для определения языка) фичи-символьные n-граммы решительно рулят.\n",
    "\n",
    "Ещё одна замечательная особенность фичей-символов: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готвых анализаторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sX0FGRwaKkh"
   },
   "source": [
    "## Регулярки\n",
    "\n",
    "(если осталось время)\n",
    "\n",
    "Вообще, часто бывает так, что для конкретного случая нужен особый способ токенизации, и надо самостоятельно написать регулярку. Или, например, перед работой с текстом, надо почистить его от своеобразного мусора: упоминаний пользователей, url и так далее.\n",
    "\n",
    "Навык полезный, давайте в нём тоже потренируемся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNPIy3o_aKkh"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0VqhjrB3aKkh"
   },
   "source": [
    "### findall\n",
    "возвращает список всех найденных совпадений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UygUiar7aKki",
    "outputId": "9a2a4c33-0987-4224-9b50-be2888e34bfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcd', 'abca']\n"
     ]
    }
   ],
   "source": [
    "result = re.findall('ab+c.', 'abcdefghijkabcabcxabc') \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qV45Zw0IaKki"
   },
   "source": [
    "**Задание**: вернуть список первых двух букв каждого слова в строке, состоящей из нескольких слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "L3gUhCbpaKki"
   },
   "outputs": [],
   "source": [
    "\"мама мыла раму\" [\"ма\", \"ма\", \"ра\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgL_WhPiaKki"
   },
   "source": [
    "### split\n",
    "разделяет строку по заданному шаблону\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXz3LEbnaKki",
    "outputId": "3e8181e8-3673-4161-8b55-bb0dceb1c80b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['itsy', ' bitsy', ' teenie', ' weenie']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(',', 'itsy, bitsy, teenie, weenie') \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roSwTdXLaKki"
   },
   "source": [
    "можно указать максимальное количество разбиений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OOwf3CMyaKki",
    "outputId": "a0a79e6b-2e67-4ea6-a63d-a646173ee5c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['itsy', ' bitsy', ' teenie, weenie']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(',', 'itsy, bitsy, teenie, weenie', maxsplit = 2) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7UtwMW2aKkj"
   },
   "source": [
    "**Задание**: разбейте строку, состоящую из нескольких предложений, по точкам, но не более чем на 3 предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "4B_qwQg0aKkj"
   },
   "outputs": [],
   "source": [
    "\"был хороший день. на улице падал снег. машины ездили по улице. было пасмурно.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19UpYsRzaKkj"
   },
   "source": [
    "### sub\n",
    "ищет шаблон в строке и заменяет все совпадения на указанную подстроку\n",
    "\n",
    "параметры: (pattern, repl, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nkLcsGv1aKkj",
    "outputId": "0e41fa76-ec42-48cb-9a9d-85f104c8a26f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbcbbc\n"
     ]
    }
   ],
   "source": [
    "result = re.sub('a', 'b', 'abcabc')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lD6c7U2kaKkj"
   },
   "source": [
    "**Задание**: напишите регулярку, которая заменяет все цифры в строке на \"DIG\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "wQeanQAMaKkj"
   },
   "outputs": [],
   "source": [
    "\"48ff9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6ZOLyuPaKkk"
   },
   "source": [
    "Если всё ещё осталось время: [регулярочный кроссворд ¯\\_(ツ)_/¯](https://mariolurig.com/crossword/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sem03_preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
